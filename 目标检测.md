# 单步模型和两步模型

* 单步模型：

  没有显式的、独立的提取候选区域的，直接由输入图像得到其中的物体的类别和位置信息

* 两步模型：

  有独立的、显式的提取候选区域的步骤，

  即先在输入图像上筛选出一部分可能存在物体的候选区域，然后针对每个区域判断其是否存在物体及其类别



比较：

* 单步模型在计算效率上有优势，两步模型在结果精度上有优势



差异的原因：

1. 多数单步模型利用了预设的anchor来捕捉可能存在的物体，由于anchor的数量远多于实际存在的物体数量，因而在训练时该分类器会面临正负样本数量极不均衡的问题，导致分类器训练效果不佳。RetinaNet使用Focal Loss来抑制负样本对最终损失的贡献来提升网络表现。

   两步模型在第一步可以筛选掉大部分不含有待检测物体的候选区域，不存在正负样本数不均衡的问题。

2. 两步模型会在区域提取时对候选区域的位置和大小进行修正，故而在进入第二步前，候选区域的特征就已经被对齐了，有利于第二次分类精度的提高。

   单步模型的各个anchor的的预测基于该层上每个特征点的感受野，输入特征未被对齐，所以定位和分类的精度容易受到影响

3. 两步模型的第二步，即对候选区域进行分类和位置回归时，是对每个候选区域独立进行的，因此该部分的算法复杂度与候选区域数目线性相关，往往十分巨大。导致其相比起单步模型仍存在计算量大，计算速度慢的问题。



* 常见模型：

  ​	单步模型：

  ​		典型：OverFeat、SSD、 YOLO

  ​		最新：CornerNet、RefineDet、ExtremeNet

  

  ​	两步模型:

  ​		典型：R-CNN、SPPNet、Fast R-CNN、Faster R-CNN、R-FCN、Mask R-CNN

  ​		较新：PANet、Cascade R-CNN、Mask Score R-CNN





# R-CNN, SPPNet, Fast R-CNN, Faster R-CNN

## R-CNN

1. 无监督的Selective Search: 

   输入图像中具有相似颜色直方图特征的区域进行递归合并，产生约2000个候选区域

2. CNN提取候选区域特征：

   截取候选区域图像，缩放到合适尺寸，送入CNN提取特征

3. 提取的特征使用SVM进行物体分类以及一个线性回归器进行边界框位置和大小的修正

4. 对检测结果进行NMS操作，得到结果



## SPPNet

针对R-CNN的两个缺陷的改进：

1. SSPNet可以接受不同size的输入特征。

   SVM分类器和线性回归器需要的输入特征的size是固定的，因此CNN的输出特征size也应该是固定的，在R-CNN中采用了将候选区域缩放到统一尺寸的办法解决该问题，但是会破坏原区域图像的长宽比，并且损失一些信息。在SPPNet中使用了空间金字塔池化（Spatial Pyramid Pooling）解决此问题。

   

   **空间金字塔池化**：

   可以接受任何尺寸的特征图作为输入，通过3个窗口大小可变但是窗口个数固定的池化层，最终输出具有固定尺寸的池化特征。

   

2. SPPNet只进行一次全图的CNN特征提取

   R-CNN中针对每一个候选区域进行特征提取，而候选区域又是大量重叠的，导致了大量重复计算。在SPPNet中只计算一次全图特征，每个候选区域的特征直接在全图特征上提取，然后输入到 空间金字塔池化层中做尺寸的统一



## Fast R-CNN

思想与SPPNet基本一致，区别在于使用的不是空间金字塔池化而是 Region-of-Interest Pooling

**Region-of-Interest Pooling**：

1. 将候选区域划分为相同大小的sections（sections的size与输出维度相同）
2. 对每个sections进行max pooling



另一改进为使用全连接网络取代了svm分类器和线性回归器。增强了检测任务的一致性，提高了效率



## Faster R-CNN

使用Region Proposal Network代替SS来提取候选区域，且这个RPN和用于检测的Fast R-CNN的网络的特征提取部分共享权值参数。





# YOLO



## YOLO

使用一个端到端的卷积神经网络直接预测目标的位置和类别。

将图片分为 S*S个方格，每个方格需要检测出中心点位于该方格内的物体，实际实施时每个方格会预测B个边界框

主体结构参考GoogLeNet，由24个卷积层和2个全连接层组成



## YOLOv2

YOLO的两个缺点：低召回率、低定位准确率

YOLOv2的改进

1. 卷积层后面加入BN层，加快收敛，防止过拟合

2. 卷积特征提取器在进行检测任务前，现在高精度的图片上fine-tune10个batch，使检测模型可以提前适应高分辨率图像

3. 采用k-means算法聚类获取先验anchor，并且聚类改进了距离的定义：
   $$
   d(box, centroid)=1-IOU(box, centroid)
   $$

4. 在预先设定的anchor上提取特征。
5. 输入图像的尺寸由448 X 448变成416 X 416，图像经过卷积层后变为13 X 13 （416/32=13）的特征图，长宽都是奇数，可以有效地识别中心
6. 最后一个池化层的输入26X26X512经过直通层变为13X13X2048的特征图，再与池化后的13X3X1024的特征图结合在一起进行物体检测
7. 使用不同尺寸的图片同时训练网络
8. 使用DarkNet-19卷积网络提取特征，没有使用VGG16，VGG16虽然效果良好，但是参数过多，运行缓慢。



## YOLO9000

实时检测9000种物体

主要贡献：

使用检测数据集和分类数据集进行联合训练，YOLO9000模型构建了字典树，合并ImageNet的分类数据集和COCO的检测数据集标签



## YOLOv3

1. 使用二元交叉熵损失函数而不是softmax
2. 使用了更深的网络 DarkNet-53，为了避免梯度消失，还使用了类似于残差网络的快捷连接结构
3. 采用3个不同大小的特征图进行联合训练，在小物体检测上获取了不错的性能



## 如何增强模型对小物体的检测能力

1. 模型设计方面：使用特征金字塔、沙漏结构等网络子结构来增强网络对多尺度尤其是小尺度特征的感知和处理能力；尽可能提升网络的感受野，是的网络能够更多的利用上下文信息来增强检测效果；减少网络总的下采样比例，使得最后检测的特征分辨率更高
2. 提高训练数据集中小物体样本占总样本的比例，可使用数据增强手段缩小图像生成小物体样本
3. 计算量允许的范围内使用更大的输入图像尺寸

